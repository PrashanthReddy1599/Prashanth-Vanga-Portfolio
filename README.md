# 📊 Data Engineering Portfolio

## 👋 About Me

Data Engineer with 4+ years of experience building scalable, cloud-native data solutions that process TB-scale datasets. I specialize in designing and optimizing ETL/ELT pipelines, real-time streaming applications, and analytics-ready data models that empower data-driven decision-making.

**Current Role:** Data Engineer @ CVS Health (Dallas, TX)  
**Education:** M.S. in Business Analytics - University of Texas at Arlington (May 2024)  
**Certification:** Google Cloud Certified Professional Data Engineer (August 2024)

## 🛠️ Core Skills

### Programming & Scripting
- **Languages:** Python, SQL, PySpark, Scala, R
- **Data Processing:** Apache Spark, Apache Kafka, Databricks, Apache Airflow

### Cloud Platforms & Services
- **AWS:** S3, Redshift, EMR, Lambda, Glue
- **GCP:** BigQuery, Dataflow, Pub/Sub, Dataproc, Cloud Storage

### Data Storage & Warehousing
- **Warehouses:** Snowflake, Redshift, BigQuery, Teradata
- **Databases:** PostgreSQL, Cloud SQL, MongoDB, Cassandra

### Data Engineering & Analytics
- Pipeline Development (Batch & Streaming)
- Data Modeling (Star & Snowflake Schemas)
- Data Quality & Validation Frameworks
- Performance Optimization (Partitioning, Clustering, Indexing)

### Orchestration, CI/CD & Tools
- Apache Airflow, Jenkins, Azure Data Factory
- Git, Docker, JIRA, REST APIs
- Power BI, Tableau, scikit-learn, pandas, numpy

## 💼 Professional Highlights

### CVS Health | Data Engineer (Jan 2024 - Present)
- Built batch and streaming pipelines processing **1.5TB daily** using Kafka, Spark, and Airflow
- Optimized ETL workflows with Python, Airflow, and AWS Lambda, **improving pipeline performance by 40%**
- Enhanced Redshift and Snowflake query performance by **35% through strategic partitioning and clustering**
- Automated ETL/ELT pipelines with Airflow, **reducing manual intervention by 50%**
- Developed Power BI dashboards for executive stakeholders, **improving decision-making speed by 30%**
- Implemented ML models for predictive analytics on patient medication adherence, achieving **85% accuracy**
- Ensured compliance with GDPR, HIPAA, and SOC 2 standards through encryption, RBAC, and audit logging

### Infosys | Data Engineer (Aug 2020 - Dec 2022)
- Built batch and streaming data pipelines in Python and PySpark for large-scale distributed systems
- Designed dimensional models (star & snowflake schemas), **improving query efficiency by 40% and storage utilization by 25%**
- Developed real-time ingestion pipelines with Dataflow, Kafka, and Pub/Sub, **reducing reporting delays from hours to minutes**
- Leveraged BigQuery with partitioning and clustering strategies, **reducing costs by 30%**
- Automated deployment workflows using Jenkins CI/CD pipelines, **reducing manual effort by 60%**
- Improved operational stability through proactive monitoring, **reducing downtime incidents by 45%**
- Achieved **99.5% data accuracy** through comprehensive quality checks and validation routines

## 🚀 Featured Projects

Explore detailed project documentation in the [`/projects`](./projects) folder:

### 1. Real-Time Healthcare Data Pipeline
**Technologies:** Apache Kafka, Spark Streaming, AWS Lambda, Redshift, Airflow

- Architected end-to-end streaming pipeline processing 1.5TB daily from multiple healthcare sources
- Implemented real-time data validation and quality checks ensuring 99.8% data accuracy
- Reduced data latency from 4 hours to under 5 minutes through optimized streaming architecture
- [View Details →](./projects/realtime-healthcare-pipeline.md)

### 2. Cloud Data Warehouse Optimization
**Technologies:** Snowflake, BigQuery, Python, dbt, Apache Airflow

- Redesigned data warehouse schema using dimensional modeling (star schema)
- Applied partitioning, clustering, and indexing strategies across 500+ tables
- Achieved 35% improvement in query performance and 30% reduction in cloud costs
- [View Details →](./projects/data-warehouse-optimization.md)

### 3. Performance Management System (Academic Project)
**Technologies:** Google Dataflow, Apache Beam, BigQuery, Cloud SQL

- Built large-scale data processing pipelines transforming 500K+ XML records daily to CSV format
- Designed 18 custom KPIs for network performance monitoring using dimensional modeling
- Enhanced anomaly detection by 20% and reduced query latency by 15% through Cloud SQL optimizations
- [View Details →](./projects/performance-management-system.md)

## 📂 Repository Structure

```
data-engineering-portfolio/
├── README.md                          # This file
├── skills.md                          # Detailed technical skills breakdown
├── projects/                          # Project deep-dives
│   ├── realtime-healthcare-pipeline.md
│   ├── data-warehouse-optimization.md
│   └── performance-management-system.md
└── docs/                              # Additional documentation
```

## 📈 Impact & Results

- **Performance Improvements:** Optimized pipelines and queries delivering 35-40% faster execution
- **Cost Optimization:** Reduced cloud infrastructure costs by 30% through strategic architecture
- **Automation:** Decreased manual intervention by 50-60% through intelligent pipeline orchestration
- **Data Quality:** Maintained 99.5%+ accuracy across production data systems
- **Scale:** Processing terabyte-scale datasets daily across distributed cloud environments

## 🎯 What I'm Looking For

I'm passionate about solving complex data challenges and building scalable solutions that drive business value. I'm open to opportunities where I can:

- Architect and build enterprise-scale data platforms
- Lead data engineering initiatives and mentor teams
- Work with cutting-edge technologies in cloud-native environments
- Contribute to data-driven decision making at scale

## 📫 Let's Connect

Interested in discussing data engineering, cloud architecture, or potential opportunities?

- **LinkedIn:** [Connect with me](https://linkedin.com/in/prashanth-vanga)
- **Email:** prashanth.vanga1599@gmail.com
- **Location:** Dallas, TX

---

### 📄 License

This repository is for portfolio and demonstration purposes. Project descriptions use anonymized data and do not contain proprietary information.

### ⭐ Feedback Welcome

If you found this portfolio helpful or have suggestions, feel free to star this repo or reach out!
