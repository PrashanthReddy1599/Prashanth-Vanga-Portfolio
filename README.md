# 📊 Data Engineering Portfolio
## 👋 About Me
Data Engineer with 4+ years of experience building scalable, cloud-native data solutions that process TB-scale datasets. I specialize in designing and optimizing ETL/ELT pipelines, real-time streaming applications, and analytics-ready data models that empower data-driven decision-making.
**Current Role:** Data Engineer @ CVS Health (Dallas, TX)
  
**Education:** M.S. in Business Analytics - University of Texas at Arlington (May 2024)
  
**Certification:** Google Cloud Certified Professional Data Engineer (August 2024)
## 🛠️ Core Skills
### Programming & Scripting
- **Languages:** Python, SQL, PySpark, Scala, R
- **Data Processing:** Apache Spark, Apache Kafka, Databricks, Apache Airflow
### Cloud Platforms & Services
- **AWS:** S3, Redshift, EMR, Lambda, Glue
- **GCP:** BigQuery, Dataflow, Pub/Sub, Dataproc, Cloud Storage
### Data Storage & Warehousing
- **Warehouses:** Snowflake, Redshift, BigQuery, Teradata
- **Databases:** PostgreSQL, Cloud SQL, MongoDB, Cassandra
### Data Engineering & Analytics
- Pipeline Development (Batch & Streaming)
- Data Modeling (Star & Snowflake Schemas)
- Data Quality & Validation Frameworks
- Performance Optimization (Partitioning, Clustering, Indexing)
### Orchestration, CI/CD & Tools
- Apache Airflow, Jenkins, Azure Data Factory
- Git, Docker, JIRA, REST APIs
- Power BI, Tableau, scikit-learn, pandas, numpy
## 💼 Professional Highlights
### CVS Health | Data Engineer (Jan 2024 - Present)
- Built batch and streaming pipelines processing **1.5TB daily** using Kafka, Spark, and Airflow
- Optimized ETL workflows with Python, Airflow, and AWS Lambda, **improving pipeline performance by 40%**
- Enhanced Redshift and Snowflake query performance by **35% through strategic partitioning and clustering**
- Automated ETL/ELT pipelines with Airflow, **reducing manual intervention by 50%**
- Developed Power BI dashboards for executive stakeholders, **improving decision-making speed by 30%**
- Implemented ML models for predictive analytics on patient medication adherence, achieving **85% accuracy**
- Ensured compliance with GDPR, HIPAA, and SOC 2 standards through encryption, RBAC, and audit logging
### Infosys | Data Engineer (Aug 2020 - Dec 2022)
- Built batch and streaming data pipelines in Python and PySpark for large-scale distributed systems
- Designed dimensional models (star & snowflake schemas), **improving query efficiency by 40% and storage utilization by 25%**
- Developed real-time ingestion pipelines with Dataflow, Kafka, and Pub/Sub, **reducing reporting delays from hours to minutes**
- Implemented data quality frameworks with Great Expectations, **achieving 99.5% accuracy**
- Migrated legacy ETL systems to cloud-native GCP, **reducing operational overhead by 60%**
- Optimized Teradata queries with indexing and partitioning, **lowering query runtimes by 50%**
## 🚀 Featured Projects
### 1. Real-Time Healthcare Data Pipeline (CVS Health)
**Technologies:** Apache Kafka, Spark Streaming, AWS (Lambda, S3, Redshift), Airflow
- Built real-time streaming pipeline ingesting 1.5TB daily from 200+ sources
- Achieved sub-2-second latency for critical healthcare events
- Implemented CDC for incremental data loads, reducing processing time by 70%
- Designed HIPAA-compliant architecture with encryption and access controls
- [View Details →](./projects/realtime-healthcare-pipeline.md)
### 2. Cloud Data Warehouse Optimization
**Technologies:** Snowflake, Redshift, Python, SQL, dbt
- Redesigned 150+ tables using star schema and slowly changing dimensions
- Implemented strategic partitioning and clustering across 50+ high-traffic tables
- Built automated data quality checks using dbt tests
- Achieved 35% improvement in query performance and 30% reduction in cloud costs
- [View Details →](./projects/data-warehouse-optimization.md)
### 3. Performance Management System (Academic Project)
**Technologies:** Google Dataflow, Apache Beam, BigQuery, Cloud SQL
- Built large-scale data processing pipelines transforming 500K+ XML records daily to CSV format
- Designed 18 custom KPIs for network performance monitoring using dimensional modeling
- Enhanced anomaly detection by 20% and reduced query latency by 15% through Cloud SQL optimizations
- [View Details →](./projects/performance-management-system.md)
## 📂 Repository Structure
```
data-engineering-portfolio/
├── README.md                          # This file
├── skills.md                          # Detailed technical skills breakdown
├── projects/                          # Project deep-dives
│   ├── realtime-healthcare-pipeline.md
│   ├── data-warehouse-optimization.md
│   └── performance-management-system.md
└── docs/                              # Additional documentation
```
## 📈 Impact & Results
- **Performance Improvements:** Optimized pipelines and queries delivering 35-40% faster execution
- **Cost Optimization:** Reduced cloud infrastructure costs by 30% through strategic architecture
- **Automation:** Decreased manual intervention by 50-60% through intelligent pipeline orchestration
- **Data Quality:** Maintained 99.5%+ accuracy across production data systems
- **Scale:** Processing terabyte-scale datasets daily across distributed cloud environments
## 🎯 What I'm Looking For
I'm passionate about solving complex data challenges and building scalable solutions that drive business value. I'm open to opportunities where I can:
- Architect and build enterprise-scale data platforms
- Lead data engineering initiatives and mentor teams
- Work with cutting-edge technologies in cloud-native environments
- Contribute to data-driven decision making at scale
## 📫 Let's Connect
Interested in discussing data engineering, cloud architecture, or potential opportunities?
- **LinkedIn:** [Connect with me](https://www.linkedin.com/in/prashanthvanga)
- **Email:** prashanth.vanga1599@gmail.com
- **Location:** Dallas, TX
---
### 📄 License
This repository is for portfolio and demonstration purposes. Project descriptions use anonymized data and do not contain proprietary information.
### ⭐ Feedback Welcome
If you found this portfolio helpful or have suggestions, feel free to star this repo or reach out!
